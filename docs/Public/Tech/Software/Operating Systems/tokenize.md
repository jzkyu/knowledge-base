To *tokenize* means to take a line of input and separate it into parts that can be individually processed by the shell. 